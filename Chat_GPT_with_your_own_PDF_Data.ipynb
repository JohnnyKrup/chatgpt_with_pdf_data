{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1N4REINIO4zXD1ZynqZU6dkUNUGdlMRYY",
      "authorship_tag": "ABX9TyO2GCtJ/XCzGLHefHb+yBBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnnyKrup/chatgpt_with_pdf_data/blob/main/Chat_GPT_with_your_own_PDF_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Chat GPT with your own data\n",
        "This Jupyter Notebook let's you use Chat GPT with your own PDF files.\n",
        "You upload multiple PDF files into a folder on your Google Drive and Chat GPT will answer your questions based on the content of your PDFs and it will also mention the source, where it found the information."
      ],
      "metadata": {
        "id": "2AFX1zOrGzM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "dtJBo2ZUGIES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-eS1XGvGCNo"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install unstructured\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Required Packages"
      ],
      "metadata": {
        "id": "YSH9oBOLGmDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The two langchain imports that we need for the PDFs and the Indexing of the data\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "c4tvFM_DITX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPEN AI KEY"
      ],
      "metadata": {
        "id": "IofpHtGhJNYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your API keys from openai\n",
        "# You will need to create an account. Create an account here: https://openai.com/\n",
        "# Here you can create openai-api-key: https://platform.openai.com/account/billing/overview\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR-OPENAI-API-KEY\""
      ],
      "metadata": {
        "id": "UwAm51CZJSyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect your Google Drive"
      ],
      "metadata": {
        "id": "0pvBI9ilKQLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect your Google Drive\n",
        "# I did not rename my Google Drive default is \"My Drive\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "root_dir = \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBxIZPOIKcCD",
        "outputId": "9d37c570-a357-4c80-ab96-9f3af1b83d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add a folder ( I called mine: data) into the folder where your Colab Notebook is.\n",
        "# I added an AI-Index Report 24MB (English) and a German document 4.5MB to my drive to test different sceanrios\n",
        "# Remember the more MB your documents have the more expensive the embedding process is.\n",
        "pdf_folder_path = f'{root_dir}/data/'\n",
        "os.listdir(pdf_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1YQpnA0K_eX",
        "outputId": "6902b45c-ad49-4302-8afc-822fa2eb1940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI-Index-Report_2023.pdf', 'obligationenrecht.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the PDF Files"
      ],
      "metadata": {
        "id": "TEtKPSS0LjW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over the files in your folder and use the UnstructuredPDFLoader from langchain to create your loader\n",
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]"
      ],
      "metadata": {
        "id": "AXUH8TxqLnNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the loaders were created\n",
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAVs5dM1MaA9",
        "outputId": "a561dc27-10ae-473e-f1c0-4228deb272a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x79672fe739a0>,\n",
              " <langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x796760db2590>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Store\n",
        "Chroma is used as a vectorstore to index and search the embeddings\n",
        "\n",
        "When using the VectorstoreIndexCreator three things are happening:\n",
        "\n",
        "- Splitting documents into chunks\n",
        "\n",
        "- Creating embeddings for each document\n",
        "\n",
        "- Storing documents and embeddings in a vectorstore"
      ],
      "metadata": {
        "id": "ZbwLE3vQMgWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start the splitting, embedding and storing of your data\n",
        "index = VectorstoreIndexCreator().from_loaders(loaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2EG39AtM_wO",
        "outputId": "fe747447-854c-4350-a218-07d47bda6243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the index was created\n",
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLNkUbFWgQVB",
        "outputId": "e84978d7-8b2e-4178-cb0d-ef15ad0436ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x79672fe73910>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asking Questions\n",
        "You can query the index to output just the answer:\n",
        "`index.query('Which gender is more open towards AI?')`\n",
        "or you can also query the index and also return the source."
      ],
      "metadata": {
        "id": "jYRh5A5IhOpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.query_with_sources(\"Which 3 specialized skills were found in job postings in the US in 2022 and what's the difference in demand compared to 2010-2012?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0QLMTHkiSTU",
        "outputId": "9d903857-6186-4493-cf9c-1d432b911375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': \"Which 3 specialized skills were found in job postings in the US in 2022 and what's the difference in demand compared to 2010-2012?\",\n",
              " 'answer': ' The top 3 specialized skills found in job postings in the US in 2022 were Python (Programming Language), Computer Science, and SQL (Programming Language). The demand for these skills increased by 592%, 63%, and 153% respectively compared to 2010-2012.\\n',\n",
              " 'sources': '/content/drive/My Drive/Colab Notebooks/data/AI-Index-Report_2023.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disclaimer:\n",
        "Note: Calling the API in the way demonstrated in this example will incur monetary charges. Refer to OpenAI's pricing information for details.\n",
        "Here you can check your usage: https://platform.openai.com/account/usage\n",
        "\n",
        "Be aware that information, such as files to train OpenAI's LLM can become public if applied in the way this demo demonstrates. Refer to OpenAI's usage policy for details.\n",
        "\n",
        "Do not use for actual tax filing purposes. This demo is for educational purposes only and for demonstrating machine learning methods. The author makes no claims that the outcomes shown here or any outcomes that could be produced by this method are accurate or reliable."
      ],
      "metadata": {
        "id": "FCVr2ey9jWYi"
      }
    }
  ]
}